install.packages("easystats")
install.packages("insight")
?insight
# An idea to use exponential Iv in non-linear regression model
# first run lrm to get coefficient
log_proprio <- log(abs(proprio_diff+.0001))
#-----------------------------#
# Loading missing package FUN #
#-----------------------------#
using <- function(...) { ## Retrieved from https://stackoverflow.com/users/4125693/matthew
libs <- unlist(list(...))
req <- unlist(lapply(libs, require, character.only = TRUE))
need <- libs[req == FALSE]
n <- length(need)
if (n > 0) {
libsmsg <- if (n > 2) paste(paste(need[1:(n - 1)], collapse = ", "), ",", sep = "") else need[1]
print(libsmsg)
if (n > 1) {
libsmsg <- paste(libsmsg, " and ", need[n], sep = "")
}
libsmsg <- paste("The following packages could not be found: ", libsmsg, "\n\r\n\rInstall missing packages?", collapse = "")
if (winDialog(type = c("yesno"), libsmsg) == "YES") {
install.packages(need)
lapply(need, require, character.only = TRUE)
}
}
}
#-------------------#
# Reformatting data #
#-------------------#
using("dplyr", "ggplot2",
"ggstatsplot", "hrbrthemes",
"ggpubr", "ggdendro",
"gridExtra","car",
"quantreg","emmeans")
setwd("C:/Users/jpmonteagudo/Desktop/R/Review/Data")
balance_df <- read.csv("balance_study.csv", sep = ",", header = TRUE)
balance_df <- balance_df[-c(67:104), ]
names(balance_df)[names(balance_df) == "After_Prorio"] <- "After_Proprio"
str(balance_df) # Checking data frame structure
cols <- c(5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17) # Converting from char to numeric
for (i in cols) {
balance_df[, i] <- round(as.numeric(gsub("%", "", balance_df[, i])), 0)
}
balance_df$Gender <- as.factor(balance_df$Gender)
balance_df$Glasses_FVE <- c(0,1) # 0 = No, 1 = Yes
print(table(balance_df$Gender)) # 2x more females than males w/ mTBI
print(table(balance_df$Glasses_FVE))
str(balance_df) # Checking data frame structure after reformatting
#------------------------------------------#
# Normality tests (graphical)              #
#------------------------------------------#
# Created function to calculate skewness of vars in df
skewness <- function(x, na.rm = FALSE) {
if (is.data.frame(x) || is.matrix(x)) {
if (na.rm) {
x <- apply(x, 2, function(column) column[!is.na(column)])
}
skew <- apply(x, 2, function(column) {
n <- length(column)
skewness <- (sum((column - mean(column))^3) / (n * sd(column)^3))
return(skewness)
})
} else {
if (na.rm) {
x <- x[!is.na(x)]
}
n <- length(x)
skew <- (sum((x - mean(x))^3) / (n * sd(x)^3))
}
return(skew)
}
# Created function to calculate kurtosis of vars in df.
kurtosis <- function(x, na.rm = FALSE) {
if (is.data.frame(x) || is.matrix(x)) {
if (na.rm) {
x <- apply(x, 2, function(column) column[!is.na(column)])
}
kurt <- apply(x, 2, function(column) {
n <- length(column)
kurtosis <- (sum((column - mean(column))^4) / (n * sd(column)^4)) - 3
return(kurtosis)
})
} else {
if (na.rm) {
x <- x[!is.na(x)]
}
n <- length(x)
kurt <- (sum((x - mean(x))^4) / (n * sd(x)^4)) - 3
}
return(kurt)
}
# Creating summary df of vars mean, skew, and kurtosis.
var_stats <- t(data.frame(lapply(balance_df[, -(1:2)], function(x) {
mean_val <- mean(x, na.rm = TRUE) # Calculate mean
skew_val <- skewness(x, na.rm = TRUE) # Calculate skewness
kurt_val <- kurtosis(x, na.rm = TRUE) # Calculate kurtosis
return(round(c(Mean = mean_val, Skewness = skew_val, Kurtosis = kurt_val), 2))
})))
print(var_stats)
# Evaluating distance between data points and vars (Mahalanobis distance & 1-cor)
balance_center <- colMeans(balance_df[, 3:9]) # Calculating center for each var.
balance_cov <- cov(balance_df[, 3:9]) # Calculating cov. for each var
distance <- mahalanobis(balance_df[, 3:9], balance_center, balance_cov)
cutoff <- qchisq(p = .90, df = ncol(balance_df[, 3:9])) # Calculating cutoff point (p = .90, df = 7)
probable_outlier <- balance_df[, 3:9][distance > cutoff, ] # Returning data points > cutoff value
outlier_with_mean <- as.data.frame(rbind(probable_outlier, var_stats[1:7, 1]))
rownames(outlier_with_mean)[nrow(outlier_with_mean)] <- "Mean" # Adding mean to each column of prob. outliers
print(outlier_with_mean) # 12% of sample probable outlier
# id 24 0 scores on pre-treatment measures
cor_dist <- round(as.dist((1 - cor(balance_df[, 3:9] / 2))) * 1000) # Using correlation between vars as distance.
# As correlation gets stronger, distance between vars gets closer
hc <- hclust(cor_dist, "complete") # Representing distance as hierarchical cluster
hc_plot <- ggdendrogram(hc, rotate = FALSE, size = 2)
print(hc_plot)
# Created function to convert percentile scores to z-scores for density plots
standardize <- function(x, ..., na.rm = FALSE) {
if (is.data.frame(x) || is.matrix(x)) {
if (na.rm) {
x <- apply(x, 2, function(column) column[!is.na(column)])
}
z_score <- apply(x, 2, function(column) {
avg <- mean(column)
stdev <- sd(column)
z_score <- (column - avg) / stdev
return(z_score)
})
return(z_score)
} else {
if (na.rm) {
x <- x[!is.na(x)]
}
avg <- mean(x)
stdev <- sd(x)
z_score <- (x - mean(x)) / sd(x)
return(z_score)
}
}
gender_plot <- ggplot(balance_df, aes(Gender, fill = Gender)) +
geom_bar(width = .4) +
scale_fill_hue(c = 40) +
facet_grid(vars(Glasses_FVE)) +
theme_light() +
ggtitle("Barplot showing number of patients (by gender) wearing glasses at start of FVE") +
theme(plot.title = element_text(family = "", face = "italic", color = "black", size = 12))
print(gender_plot)
# Standardizing Cumulative results variable prior to plotting density
balance_df$zPre_Cumul <- standardize(balance_df$Pre_Cumul)
balance_df$zAfter_Cumul <- standardize(balance_df$After_Cumul)
balance_df$zChange_Cumul <- standardize(balance_df$Change_Cumul)
# Plotting standardized pre/after proprioception measurements.
cumul_density <- ggplot(balance_df, aes(zPre_Cumul)) +
geom_density(aes(zPre_Cumul, y = after_stat(density)), fill = "#69b3a2") +
geom_label(aes(3.5, .25, label = "Pre_Cumul"), color = "#69b3a2") +
geom_density(aes(zAfter_Cumul, y = -after_stat(density)), fill = "#404080") +
geom_label(aes(3.5, -.25, label = "After_Cumul"), color = "#404080") +
theme_ipsum() +
xlab("Cumulative measurement before and after FVE") +
theme_light() +
ggtitle("Density plot comparing Cumulative measurements before and after FVE") +
theme(plot.title = element_text(family = "", face = "italic", color = "black", size = 12))
print(cumul_density)
# Created function to display Q-Q plots for numeric variables in df.
QQ_plots <- function(data, cols, show_labels = TRUE) { # labeling y-axis to identify vars
qq_plots <- list()
for (col in cols) { # cols is a vector containing the desired columns
plot <- ggqqplot(data[[col]]) # requires ggpubr, gridExtra and ggplot2
col_name <- colnames(data)[col]
if (show_labels) {
plot <- plot + labs(y = col)
}
qq_plots[[col]] <- plot
}
qq_panel <- do.call(grid.arrange, qq_plots)
return(qq_panel)
}
cols <- colnames(balance_df[,3:13])
print(QQ_plots(balance_df,cols))
# Created function to display histograms for numeric vars in df.
histograms <- function(data, cols) {
hist_plots <- list()
for (col in cols) {
plot <- ggplot(data, aes(x = .data[[col]])) +
geom_histogram(binwidth = 2.5, fill = "#69b3a2", color = "#404080") +
labs(x = col, y = "Frequency") +
theme_minimal()
hist_plots[[col]] <- plot
}
hist_panel <- do.call(grid.arrange, hist_plots)
return(hist_panel)
}
cols <- colnames(balance_df[,3:13])
print(histograms(balance_df,cols))
# Created correlation matrix to assess independence.
corr_matrix <- ggcorrmat(balance_df,
method = "kendall", # Correlation matrix
label = TRUE, # assuming normality
cor.vars = c(
"Age", "months_mTBI", "Pre_Proprio",
"Pre_Visual", "Pre_Vest", "Pre_Cumul",
"weeks_glasses", "After_Proprio",
"After_Visual", "After_Vest", "After_Cumul"
),
title = "Correlation matrix",
size = 2
)
print(corr_matrix)
# Scatterplot matrix
my_cols <- c("#00AFBB", "#E7B800")
panel.cor <- function(x, y){
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- round(cor(x, y,method = "kendall"), digits=2)
txt <- paste0("R = ", r)
cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
# Customize upper panel
upper.panel<-function(x, y){
points(x,y, pch = 19, col = my_cols[balance_df$Glasses_FVE], cex = 1.5)
}
pairs(balance_df[,3:8],
upper.panel = upper.panel,
lower.panel = panel.cor)
pairs(balance_df[,c(3,4,10,11,12,13,17)],
upper.panel = upper.panel,
lower.panel = panel.cor)
#-------------------------------#
# Normality test (numerical)    #
#-------------------------------#
normality_shapiro_test <- data.frame(t(sapply(balance_df[,c(3:13,17)], shapiro.test))) # Data violates normality assumption
non_normal <- normality_shapiro_test[normality_shapiro_test$p.value <= .05,]; print(non_normal) # Non-normal data
homogeneity_test<- t(sapply(balance_df[,c(3:13,17)], function(x) bartlett.test(x~Glasses_FVE,balance_df))) # Equal variances assumed
# Visualizing difference in visual measurements in each group
boxplots <- function(data, cols) {
boxplot_plots <- list()
for (col in cols) {
plot <- ggplot(data, aes(x = Glasses_FVE, y = .data[[col]])) +
geom_boxplot(fill = "steelblue", color = "black") +
labs(x = "Wearing glasses at start of FVE", y = col) +
theme_minimal()
boxplot_plots[[col]] <- plot
}
boxplot_panel <- do.call(grid.arrange, boxplot_plots)
return(boxplot_panel)
}
print(boxplots(balance_df,cols))
#----------------------------------------#
# Using QR to assess effect of treatment #
# on all patients                        #
#----------------------------------------#
stacked <- stack(data.frame(balance_df$Pre_Cumul,balance_df$After_Cumul))
qr_test <- summary(rq(values~ind, tau = .5, data = stacked), se = "boot", R = 9999)
print(qr_test)
emmeans_mod <- emmeans(rq(values~ind, tau = .5, data = stacked), ~ind)
print(emmeans_mod)
pairs(emmeans_mod)
#----------------------------------------#
# Using QR to assess effect of treatment #
# on patients with and w/o glasses       #
#----------------------------------------#
taus <- c(.05,.15,.25,.50,.75,.95)
qr_test2 <- summary(rq(Change_Cumul ~ Glasses_FVE+weeks_glasses+Age,
taus, data = balance_df), se = "boot", R = 9999)
print(qr_test2)
emmeans_model <-  emmeans(rq(Change_Cumul ~ Glasses_FVE, data = balance_df), ~Glasses_FVE)
print(emmeans_model)
pairs(emmeans_model)
#----------------------------------------------#
# Wilcoxon signed-rank test for pseudo-medians #
# (data not iid nor symmetric)                 #
#----------------------------------------------#
# Difference in medians
median(balance_df$Pre_Cumul)- median(balance_df$After_Cumul)
# [1] -34
# (Pseudo)median:
median(outer(balance_df$Pre_Cumul,balance_df$After_Cumul,"-"))
# [1] -29
# Visualizing  median difference
layout(matrix(c(1, 2), nrow = 2))
par(mar = c(5, 4, 2, 1))  # Adjust the margins for the first plot
hist(balance_df$Pre_Cumul, xlim = c(-20, 100), col = "steelblue", lwd = 2,
main = "Histogram of Pre-Cumulative Balance measures")
abline(v = median(balance_df$Pre_Cumul), col = "gold", lwd = 2) # gold line showing median
main = "Histogram of Pre-Cumulative Balance measures"
par(mar = c(5, 4, 2, 1))  # Adjust the margins for the second plot
hist(balance_df$After_Cumul, xlim = c(-20, 100), col = "steelblue", lwd = 2,
main = "Histogram of Post-Cumulative Balance measures")
abline(v = median(balance_df$After_Cumul), col = "gold", lwd = 2) # gold line showing median
wilcox.test(balance_df$Pre_Cumul, balance_df$After_Cumul,alternative = "two.sided", paired = TRUE, conf.int = T, conf.level = .90)
# Wilcoxon signed rank test with continuity correction for diff. in pre/after measures
# data:  balance_df$Pre_Cumul and balance_df$After_Cumul
# V = 0, p-value = 1.669e-12
# alternative hypothesis: true location shift is not equal to 0
# 90 percent confidence interval:
#  -31.00004 -25.00000
# sample estimates:
# (pseudo)median
# -27.99998
wilcox.test(Change_Cumul ~ Glasses_FVE, balance_df, paired = TRUE, conf.int = TRUE, conf.level = .90)
# Wilcoxon signed rank test with continuity correction by Glasses_FVE groups
# data:  Change_Cumul by Glasses_FVE
# V = 317.5, p-value = 0.514
# alternative hypothesis: true location shift is not equal to 0
# 90 percent confidence interval:
#   -3.999989  7.999987
# sample estimates:
#  (pseudo)median
# 1.999963
# Density plot showing distribution of Cumulative changes for patients w. and w/o glasses
change_density <- ggplot(balance_df, aes(zChange_Cumul)) +
geom_density(aes(zChange_Cumul, y = after_stat(density)), fill = "#69b3a2") +
geom_label(aes(3.5, .25, label = "Change_Cumul"), color = "#69b3a2") +
facet_wrap(~Glasses_FVE, ncol =1 , strip.position = "right", scales = "free_y") +
theme_ipsum() +
xlab("Change in Cumulative Balance Measurement") +
theme_light() +
ggtitle("Density plot comparing Change in Cumulative measurements by groups") +
theme(plot.title = element_text(family = "", face = "italic", color = "black", size = 12))
print(change_density)
# Histogram showing distribution of Cumulative changes for patients w. and w/o glasses
no_glasses <- balance_df$Change_Cumul[balance_df$Glasses_FVE == 0] # storing Glasses_FVE Change Cumul in new vars
glasses <- balance_df$Change_Cumul[balance_df$Glasses_FVE == 1]
layout(matrix(c(1, 2), nrow = 2))
par(mar = c(5, 4, 2, 1))  # Adjust the margins for the first plot
hist(no_glasses, xlim = c(-20, 100), col = "steelblue", lwd = 2,
xlab = "Change_Cumul",
main = "Histogram of Change in Cumulative measures for patients w. no glasses")
abline(v = median(no_glasses), col = "gold", lwd = 2) # gold line showing median
main = "Histogram of Change in Cumulative Balance measures"
par(mar = c(5, 4, 2, 1))  # Adjust the margins for the second plot
hist(glasses, xlim = c(-20, 100), col = "steelblue", lwd = 2,
xlab = "Change_Cumul",
main = "Histogram of Change in Cumulative measures for patients w. glasses")
abline(v = median(glasses), col = "gold", lwd = 2) # gold line showing median
# Difference in medians
median(no_glasses) - median(glasses)
# [1] 3
# (Pseudo)median:
median(outer(no_glasses,glasses,"-"))
# [1] 1
# An idea to use exponential Iv in non-linear regression model
# first run lrm to get coefficient
log_proprio <- log(abs(proprio_diff+.0001))
# Trying to figure out the distribution of residuals for a possible model
summary(pred_change <- lm(Change_Cumul ~ Age + Change_Visual + Change_Vest + Gender,balance_df)) # creating model to get residuals
residuals <- pred_change$residuals # Getting residuals and plotting to check variance
layout(matrix(c(1:4), nrow = 2))
plot(residuals)
abline(h = median(residuals), col = "red", lwd = 2)
car::densityPlot(residuals)
hist(residuals)
dev <- no_glasses - mean(no_glasses)
hist(dev)
car::densityPlot(dev)
# Visualizing iV vs. dV
cumul_diff <- balance_df$Change_Cumul
gender <- balance_df$Gender
weeks <- balance_df$weeks_glasses
vars_to_plot <- list( # storing columns in var for easy manipulation
age <- balance_df$Age,
visual_diff <- balance_df$Change_Visual, # quadratic?
vest_diff <- balance_df$Change_Vest,
proprio_diff <- balance_df$Change_Proprio) # exponential? (exp(beta*proprio_diff))
for(var in vars_to_plot) {
car::scatterplot(var, cumul_diff, smooth = TRUE)
}
cols <- c("Change_Proprio","Change_Visual","Change_Vest","Change_Cumul")
histograms(balance_df, cols)
change_stats <- t(data.frame(lapply(balance_df[,14:17], function(x) {
mean_val <- mean(x, na.rm = TRUE) # Calculate mean
skew_val <- skewness(x, na.rm = TRUE) # Calculate skewness
kurt_val <- kurtosis(x, na.rm = TRUE) # Calculate kurtosis
return(round(c(Mean = mean_val, Skewness = skew_val, Kurtosis = kurt_val), 2))
})))
print(change_stats)
shapiro_test <- data.frame(t(sapply(balance_df[,14:17], shapiro.test)))
corr_test <- lapply(balance_df[,14:17], function(x) cor.test(x,cumul_diff,method = "kendall"))
# An idea to use exponential Iv in non-linear regression model
# first run lrm to get coefficient
log_proprio <- log(abs(proprio_diff+.0001))
fit_lm <- lm(cumul_diff~log_proprio) # compute absolute value of proprio_diff and add .001 to every value.
b <- coef(fit_lm)[[2]] # Extract coefficient of log(abs(proprio_diff + .001))
stacked <- stack(data.frame(cumul_diff,proprio_diff))
plot(cumul_diff,log_proprio)
layout(matrix(c(1:1)),nrow = 1)
layout(matrix(c(1:1)))
plot(cumul_diff,log_proprio)
plot(log_proprio, cumul_diff)
scatterplot(log_proprio, cumul_diff)
layout(matrix(c(1:1)))
par(mar(c(5,4,4,2)))
par(mar = c(5,4,4,2)))
par(mar = c(5,4,4,2))
scatterplot(log_proprio, cumul_diff)
hist(log_proprio)
summary(fit_lm)
lm(cumul_diff~proprio_diff)
summary(lm(cumul_diff~proprio_diff))
summary(lm(cumul_diff~log(proprio_diff)))
install.packages("caretForecast")
View(stacked)
nls(cumul_diff~ e^(b*proprio_diff),start = list(b=b),algorithm = "plinear")
nls(cumul_diff~ exp^(b*proprio_diff),start = list(b=b),algorithm = "plinear")
nls(cumul_diff~ exp(b*proprio_diff),start = list(b=b),algorithm = "plinear")
nls(cumul_diff~ exp(b*proprio_diff+.001),start = list(b=b),algorithm = "plinear")
nls(cumul_diff~ exp(b*proprio_diff+.001),start = list(b=1.372583),algorithm = "plinear")
nls(cumul_diff~ exp(b*proprio_diff+.001),start = list(b=30),algorithm = "plinear")
nls(cumul_diff~ exp(b*proprio_diff+.001),algorithm = "plinear")
nls(cumul_diff~ exp(b*proprio_diff+.001),algorithm != "plinear")
nls(cumul_diff~ exp(b*proprio_diff+.001)
nls(cumul_diff~ exp(b*proprio_diff+.001))
nls(cumul_diff~ exp(b*proprio_diff+.001))
nls(cumul_diff~ exp(b*proprio_diff+.001), algorithm = "port")
